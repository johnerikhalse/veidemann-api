syntax = "proto3";

package veidemann.api.config.v1;

import "google/protobuf/timestamp.proto";

option go_package = "github.com/nlnwa/veidemann-api-go/config/v1;config";
option java_multiple_files = true;
option java_package = "no.nb.nna.veidemann.api.config.v1";
option java_outer_classname = "ConfigResources";

message ConfigObject {
    string id = 1;
    string apiVersion = 2;
    Kind kind = 3;
    Meta meta = 4;
    oneof spec {
        veidemann.api.config.v1.CrawlEntity crawl_entity = 5;
        veidemann.api.config.v1.Seed seed = 6;
        veidemann.api.config.v1.CrawlJob crawl_job = 7;
        veidemann.api.config.v1.CrawlConfig crawl_config = 8;
        veidemann.api.config.v1.CrawlScheduleConfig crawl_schedule_config = 9;
        veidemann.api.config.v1.BrowserConfig browser_config = 10;
        veidemann.api.config.v1.PolitenessConfig politeness_config = 11;
        veidemann.api.config.v1.BrowserScript browser_script = 12;
        veidemann.api.config.v1.CrawlHostGroupConfig crawl_host_group_config = 13;
        veidemann.api.config.v1.RoleMapping role_mapping = 14;
    }
}

enum Kind {
    undefined = 0;
    crawlEntity = 5;
    seed = 6;
    crawlJob = 7;
    crawlConfig = 8;
    crawlScheduleConfig = 9;
    browserConfig = 10;
    politenessConfig = 11;
    browserScript = 12;
    crawlHostGroupConfig = 13;
    roleMapping = 14;
}

message Meta {
    string name = 1;
    string description = 2;
    google.protobuf.Timestamp created = 3;
    string created_by = 4;
    google.protobuf.Timestamp last_modified = 5;
    string last_modified_by = 6;
    repeated Label label = 7;
}

message Label {
    string key = 1;
    string value = 2;
}

// A crawl entity (might be an organisation with one or more seeds)
message CrawlEntity {
}

message Seed {
    string entity_id = 3;
    CrawlScope scope = 4;
    repeated string job_id = 5;
    bool disabled = 18;
}

message CrawlJob {
    string schedule_id = 3;
    CrawlLimitsConfig limits = 4;
    string crawl_config_id = 5;
    bool disabled = 18;
}

message CrawlConfig {
    string browser_config_id = 7;
    string politeness_id = 8;
    ExtraConfig extra = 9;
    int32 minimum_dns_ttl_s = 10; // Not implemented
    // The weighting between jobs when two jobs compete on fetching resources from the same hosts.
    // The job will be randomly choosed, but weighted such that if that two jobs with weight 1.0 and one job with
    // weight 2.0 compete, then the two first jobs will each have 25% probability of beeing choosed and the the third
    // job will have 50% probability of beeing choosed.
    double priority_weight = 11;
}

message CrawlScheduleConfig {
    string cron_expression = 3;
    google.protobuf.Timestamp valid_from = 4;
    google.protobuf.Timestamp valid_to = 5;
}

message CrawlScope {
    string surt_prefix = 1;
}

message CrawlLimitsConfig {
    // How deep from a seed to crawl
    int32 depth = 1;
    // Maximum time in seconds allowed for crawl to finish
    int64 max_duration_s = 2;
    // Maximum number of bytes to fetch before ending crawl
    int64 max_bytes = 3;
}

message BrowserConfig {
    string user_agent = 3;
    int32 window_width = 4;
    int32 window_height = 5;
    int64 page_load_timeout_ms = 6;
    // Select scripts by label
    // A string representing a label query. The query matches if at least one label matches the query.
    // If there are multiple queries, then each query must match at least one label.
    // Label quries are case insensitive. The basic format is <code>key:value</code> where both key and value must match.
    // If value ends with <code>&ast;</code> then the key must match and value must match up until the <code>&ast;</code>.
    // If value is empty, all labels matching the key will match.
    // If key is empty, then the matching is done on the value for all keys.
    // If key is empty, then the <code>:</code> might be ommitted.
    // <pre>
    // Examples:
    //   "foo:bar"  - matches exactly labels with key=foo and value=bar
    //   "foo:"     - matches all labels with key=foo
    //   ":bar"     - matches all labels with value=bar
    //   "bar"      - matches all labels with value=bar
    //   "foo:ba*"  - matches labels with key=foo and value starting with ba (e.g. matches bar, but not ber)
    //   ":ba*"     - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   "ba*"      - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   ":"        - matches every label
    //   ""         - matches every label
    // </pre>
    repeated string script_selector = 7;
    repeated string script_id = 8;
    map<string, string> headers = 16;
    map<string, string> script_parameters = 17; // Not implemented
    // Max time to wait for network activity
    int64 max_inactivity_time_ms = 18;
}

message PolitenessConfig {
    enum RobotsPolicy {
        OBEY_ROBOTS = 0;
        IGNORE_ROBOTS = 1;
        CUSTOM_ROBOTS = 2;
    }
    RobotsPolicy robots_policy = 3;
    int32 minimum_robots_validity_duration_s = 11;
    string custom_robots = 20;
    int64 min_time_between_page_load_ms = 4;
    int64 max_time_between_page_load_ms = 5;
    /**
     * The fetch time of the URI is multiplied with this value to get the delay time before fetching the next URI.
     * If min_time_between_page_load_ms and/or max_time_between_page_load_ms are set, then those values are used as
     * the upper/lower limits for delay.
     * If delay_factor is unset or zero, then a delay_facor of one is assumed. If delay_factor is negative,
     * a delay_factor of zero is assumed.
     */
    float delay_factor = 6;
    int32 max_retries = 7; // The maximum number of retries before giving up fetching a uri
    int32 retry_delay_seconds = 8;
    // Select crawl host groups by label
    // A string representing a label query. The query matches if at least one label matches the query.
    // If there are multiple queries, then each query must match at least one label.
    // Label quries are case insensitive. The basic format is <code>key:value</code> where both key and value must match.
    // If value ends with <code>&ast;</code> then the key must match and value must match up until the <code>&ast;</code>.
    // If value is empty, all labels matching the key will match.
    // If key is empty, then the matching is done on the value for all keys.
    // If key is empty, then the <code>:</code> might be ommitted.
    // <pre>
    // Examples:
    //   "foo:bar"  - matches exactly labels with key=foo and value=bar
    //   "foo:"     - matches all labels with key=foo
    //   ":bar"     - matches all labels with value=bar
    //   "bar"      - matches all labels with value=bar
    //   "foo:ba*"  - matches labels with key=foo and value starting with ba (e.g. matches bar, but not ber)
    //   ":ba*"     - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   "ba*"      - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   ":"        - matches every label
    //   ""         - matches every label
    // </pre>
    repeated string crawl_host_group_selector = 9;
    // If true, use hostname instead of ip for politeness
    bool use_hostname = 10;
}

message ExtraConfig {
    bool extract_text = 5; // Not implemented
    bool create_snapshot = 6;
}

// Message containing a javascript to be run in a browser
message BrowserScript {
    string script = 3;
    string url_regexp = 4; // Not implemented
}

message CrawlHostGroupConfig {
    message IpRange {
        string ip_from = 1;
        string ip_to = 2;
    }
    repeated IpRange ip_range = 3;
}

enum Role {
    // Any authenticated user
    ANY_USER = 0;
    // Any user including unauthenticated users
    ANY = 1;
    // Administrator
    ADMIN = 2;
    // Curator
    CURATOR = 3;
    // A user with permission to read internal data
    READONLY = 4;
}

message RoleMapping {
    oneof email_or_group {
        string email = 2;
        string group = 3;
    }
    repeated Role role = 4;
}