syntax = "proto3";

package veidemann.api.frontier.v1;

import "commons/v1/resources.proto";
import "config/v1/resources.proto";
import "google/protobuf/timestamp.proto";

option go_package = "github.com/nlnwa/veidemann-api-go/frontier/v1;frontier";
option java_multiple_files = true;
option java_package = "no.nb.nna.veidemann.api.frontier.v1";
option java_outer_classname = "FrontierResources";

message QueuedUri {
    string id = 1;
    string execution_id = 2;
    google.protobuf.Timestamp discovered_time_stamp = 3;
    // Sequence number to order the fetch of uris from a seed
    int64 sequence = 4;
    string uri = 5;
    string surt = 6;
    string ip = 7;

    /**
     * Get the discoveryPath,
     *  R - Redirect
     *  E - Embed
     *  X - Speculative embed (aggressive/Javascript link extraction)
     *  L - Link
     *  P - Prerequisite (as for DNS or robots.txt before another URI)
     */
    string discovery_path = 8;
    string referrer = 9;
    repeated Cookie cookies = 10;
    int64 page_fetch_time_ms = 11; // The time used to fetch and render the the uri including dependencies
    int32 retries = 12; // Number of times this uri has been scheduled for retry.
    google.protobuf.Timestamp earliest_fetch_time_stamp = 13; // Do not fetch this uri before this time
    string crawl_host_group_id = 14; // The Crawl Host Group calculated for this uri
    veidemann.api.config.v1.ConfigRef politeness_ref = 15; // Ref to the politeness config used when discovering this uri
    veidemann.api.commons.v1.Error error = 16; // Contains the error reason if fetch failed
    string job_execution_id = 17;
    bool unresolved = 18; // If true, then this uri is just added to the queue and no resolution of ip or robots.txt checks are done yet.
    google.protobuf.Timestamp fetch_start_time_stamp = 19;
    // The weighting between jobs when two jobs compete on fetching resources from the same hosts.
    // Copied from CrawlConfig for efficiency.
    double priority_weight = 20;
}

message Cookie {
    // Cookie name.
    string name = 1;
    // Cookie value.
    string value = 2;
    // Cookie domain.
    string domain = 3;
    // Cookie path.
    string path = 4;
    // Cookie expiration date as the number of seconds since the UNIX epoch.
    double expires = 5;
    // Cookie size.
    int32 size = 6;
    // True if cookie is http-only.
    bool http_only = 7;
    // True if cookie is secure.
    bool secure = 8;
    // True in case of session cookie.
    bool session = 9;
    // Cookie SameSite type.
    string same_site = 10;
}

message CrawlHostGroup {
    string id = 1; // SHA-1 hash of uri or crawlgroup config id
    string politeness_id = 2; // The politeness config this group is valid for
    google.protobuf.Timestamp next_fetch_time = 3; // The earliest time a URI from this group might be fetched
    bool busy = 4; // True if crawler is busy with fetching a URI from this group
    int64 queued_uri_count = 5; // The number of queued Uri's belonging to this CrawlHostGroup
}

// Metadata about a crawl execution.
// A crawl execution is the complete harvest of a seed as specified in the connected job's configuration.
message CrawlExecutionStatus {
    enum State {
        UNDEFINED = 0;
        CREATED = 1;
        FETCHING = 2;
        SLEEPING = 3;
        FINISHED = 4;
        ABORTED_TIMEOUT = 5;
        ABORTED_SIZE = 6;
        ABORTED_MANUAL = 7;
        FAILED = 8;
        DIED = 9;
    }

    string id = 1;
    State state = 2;
    string job_id = 3;
    string seed_id = 4;
    veidemann.api.config.v1.CrawlScope scope = 5;
    google.protobuf.Timestamp start_time = 6; // When this crawl execution started crawling
    google.protobuf.Timestamp end_time = 7; // When this crawl execution ended
    int64 documents_crawled = 8;
    int64 bytes_crawled = 9;
    int64 uris_crawled = 10;
    int64 documents_failed = 11;
    int64 documents_out_of_scope = 12;
    int64 documents_retried = 13;
    int64 documents_denied = 14;
    google.protobuf.Timestamp last_change_time = 15; // When this record was last updated
    google.protobuf.Timestamp created_time = 16; // When this crawl execution was created
    repeated string current_uri_id = 20;
    string job_execution_id = 21;
    veidemann.api.commons.v1.Error error = 22; // Extra description of error state
}

message CrawlExecutionStatusChange {
    string id = 1;
    CrawlExecutionStatus.State state = 2;
    google.protobuf.Timestamp end_time = 4; // When this crawl execution ended
    int64 add_documents_crawled = 5;
    int64 add_bytes_crawled = 6;
    int64 add_uris_crawled = 7;
    int64 add_documents_failed = 8;
    int64 add_documents_out_of_scope = 9;
    int64 add_documents_retried = 10;
    int64 add_documents_denied = 11;
    QueuedUri add_current_uri = 12;
    QueuedUri delete_current_uri = 13;
    veidemann.api.commons.v1.Error error = 14; // Extra description of error state
}

// Metadata about an execution of a job.
// A job execution is the sum of all crawl executions for a job at a specific time.
message JobExecutionStatus {
    enum State {
        UNDEFINED = 0;
        CREATED = 1;
        RUNNING = 2;
        FINISHED = 3;
        ABORTED_MANUAL = 4;
        FAILED = 5;
        DIED = 6;
    }

    string id = 1;
    string job_id = 2;
    State state = 3;
    map<string, int32> executions_state = 4;
    google.protobuf.Timestamp start_time = 6;
    google.protobuf.Timestamp end_time = 7;
    int64 documents_crawled = 8;
    int64 bytes_crawled = 9;
    int64 uris_crawled = 10;
    int64 documents_failed = 11;
    int64 documents_out_of_scope = 12;
    int64 documents_retried = 13;
    int64 documents_denied = 14;
    veidemann.api.commons.v1.Error error = 15; // Extra description of error state
}

message CrawlLog {
    string warc_id = 1;
    google.protobuf.Timestamp time_stamp = 2;
    string surt = 3;
    int32 status_code = 4;
    int64 size = 5;
    string requested_uri = 6;
    string response_uri = 7;

    /**
     * Get the discoveryPath,
     *  R - Redirect
     *  E - Embed
     *  X - Speculative embed (aggressive/Javascript link extraction)
     *  L - Link
     *  P - Prerequisite (as for DNS or robots.txt before another URI)
     */
    string discovery_path = 8;
    string referrer = 9;
    string content_type = 10;
    google.protobuf.Timestamp fetch_time_stamp = 11;
    int64 fetch_time_ms = 12;
    string block_digest = 13;
    string payload_digest = 14;
    string storage_ref = 15;
    string record_type = 16;
    string warc_refers_to = 17;
    string ip_address = 18;
    string execution_id = 19;
    int32 retries = 20; // Number of times this uri has been retried. Zero means success on first attempt.
    veidemann.api.commons.v1.Error error = 21; // Contains the error reason if fetch failed
    string job_execution_id = 22;
    string collection_final_name = 23;
}

// Log for each page including discovered resources and links
message PageLog {
    // A resource used to complete a page. It might be embedded images, javascripts, stylesheets etc.
    message Resource {
        string uri = 1;
        bool from_cache = 2;
        bool renderable = 3;
        string resource_type = 4;
        string mime_type = 5;
        int32 status_code = 6;
        string discovery_path = 7;
        string warc_id = 8;
        string referrer = 9;
        veidemann.api.commons.v1.Error error = 10; // Contains the error reason if fetch failed
    }

    string warc_id = 1;
    string uri = 2;
    string execution_id = 3;
    string referrer = 4;
    string job_execution_id = 5;
    string collection_final_name = 6;
    repeated Resource resource = 10;
    repeated string outlink = 11;
}
